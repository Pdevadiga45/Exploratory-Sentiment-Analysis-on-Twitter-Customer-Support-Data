!pip install transformers
!pip install datasets torch
!pip install -U accelerate
!pip install pandas matplotlib
!pip install pyarrow==14.0.1

import os
import re
import pandas as pd
import matplotlib.pyplot as plt
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset, load_metric
from sklearn.model_selection import train_test_split
import torch

class SentimentAnalyzer:
    def __init__(self, model_name='bert-base-uncased'):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_name = model_name
        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)
        self.model = BertForSequenceClassification.from_pretrained(self.model_name, num_labels=5).to(self.device)

    def clean_tweet(self, tweet):
        """Utility function to clean tweet text by removing links, special characters using simple regex statements."""
        if isinstance(tweet, str):  # Check if tweet is a string
            return ' '.join(re.sub(r"(@[A-Za-z0-9_]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)", " ", tweet).split())
        else:
            return ""  # Return an empty string for non-string values

    def preprocess_data(self, tweets):
        encodings = self.tokenizer(tweets, padding=True, truncation=True, return_tensors="pt")
        encodings = {key: tensor.to(self.device) for key, tensor in encodings.items()}
        return encodings

    def fine_tune_model(self, train_dataset, val_dataset):
        """Fine-tune the BERT model on the given dataset."""
        training_args = TrainingArguments(
            output_dir='./results',
            num_train_epochs=3,
            per_device_train_batch_size=8,
            per_device_eval_batch_size=8,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir='./logs',
            logging_steps=10,
            evaluation_strategy="epoch",
            save_strategy="epoch"
        )

        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=self.tokenizer,
            compute_metrics=self.compute_metrics
        )

        trainer.train()

    def compute_metrics(self, p):
        metric = load_metric("accuracy")
        logits, labels = p
        predictions = logits.argmax(axis=-1)
        return metric.compute(predictions=predictions, references=labels)

    def get_tweet_sentiment(self, tweet):
        """Utility function to classify the polarity of a tweet using BERT."""
        cleaned_tweet = self.clean_tweet(tweet)
        inputs = self.preprocess_data([cleaned_tweet])
        outputs = self.model(**inputs)
        prediction = outputs.logits.argmax(axis=-1).item()
        return ['very negative', 'negative', 'neutral', 'positive', 'very positive'][prediction]

    def analyze_sentiments(self, tweets_df):
        """Function to perform sentiment analysis on each tweet."""
        tweets_df['clean_text'] = tweets_df['text'].apply(self.clean_tweet)
        tweets_df['sentiment'] = tweets_df['clean_text'].apply(self.get_tweet_sentiment)
        return tweets_df

def analyze_responses_by_brand(tweets, brand):
    """Function to analyze customer responses to a specific brand's tweets."""
    brand_tweets = tweets[tweets['author_id'] == brand]

    if brand_tweets.empty:
        return 0, 0, 0, 0, 0

    # Get the tweet ids of the brand's tweets
    brand_tweet_ids = brand_tweets['tweet_id'].tolist()

    # Find customer tweets that are responses to the brand's tweets
    customer_responses = tweets[tweets['in_response_to_tweet_id'].isin(brand_tweet_ids)]

    if customer_responses.empty:
        return 0, 0, 0, 0, 0

    very_positive_responses = customer_responses[customer_responses['sentiment'] == 'very positive']
    positive_responses = customer_responses[customer_responses['sentiment'] == 'positive']
    neutral_responses = customer_responses[customer_responses['sentiment'] == 'neutral']
    negative_responses = customer_responses[customer_responses['sentiment'] == 'negative']
    very_negative_responses = customer_responses[customer_responses['sentiment'] == 'very negative']

    very_positive_percentage = 100 * len(very_positive_responses) / len(customer_responses)
    positive_percentage = 100 * len(positive_responses) / len(customer_responses)
    neutral_percentage = 100 * len(neutral_responses) / len(customer_responses)
    negative_percentage = 100 * len(negative_responses) / len(customer_responses)
    very_negative_percentage = 100 * len(very_negative_responses) / len(customer_responses)

    return very_positive_percentage, positive_percentage, neutral_percentage, negative_percentage, very_negative_percentage, len(customer_responses)

def analyze_initial_tweets_by_brand(tweets, brand):
    """Function to analyze initial customer tweets directed to a specific brand."""
    # Find initial customer tweets directed at the brand
    initial_tweets = tweets[(tweets['in_response_to_tweet_id'].isnull()) & (tweets['author_id'] != brand)]

    # Find tweets directed at the brand
    initial_tweets_to_brand = initial_tweets[initial_tweets['text'].str.contains(f"@{brand}", na=False)]

    if initial_tweets_to_brand.empty:
        return 0, 0, 0, 0, 0

    very_positive_initial_tweets = initial_tweets_to_brand[initial_tweets_to_brand['sentiment'] == 'very positive']
    positive_initial_tweets = initial_tweets_to_brand[initial_tweets_to_brand['sentiment'] == 'positive']
    neutral_initial_tweets = initial_tweets_to_brand[initial_tweets_to_brand['sentiment'] == 'neutral']
    negative_initial_tweets = initial_tweets_to_brand[initial_tweets_to_brand['sentiment'] == 'negative']
    very_negative_initial_tweets = initial_tweets_to_brand[initial_tweets_to_brand['sentiment'] == 'very negative']

    very_positive_percentage = 100 * len(very_positive_initial_tweets) / len(initial_tweets_to_brand)
    positive_percentage = 100 * len(positive_initial_tweets) / len(initial_tweets_to_brand)
    neutral_percentage = 100 * len(neutral_initial_tweets) / len(initial_tweets_to_brand)
    negative_percentage = 100 * len(negative_initial_tweets) / len(initial_tweets_to_brand)
    very_negative_percentage = 100 * len(very_negative_initial_tweets) / len(initial_tweets_to_brand)

    return very_positive_percentage, positive_percentage, neutral_percentage, negative_percentage, very_negative_percentage, len(initial_tweets_to_brand)

def plot_sentiment_analysis(brands, sentiments, title):
    """Function to plot sentiment analysis results."""
    very_positive = [sentiment[0] if len(sentiment) > 5 else 0 for sentiment in sentiments]
    positive = [sentiment[1] if len(sentiment) > 5 else 0 for sentiment in sentiments]
    neutral = [sentiment[2] if len(sentiment) > 5 else 0 for sentiment in sentiments]
    negative = [sentiment[3] if len(sentiment) > 5 else 0 for sentiment in sentiments]
    very_negative = [sentiment[4] if len(sentiment) > 5 else 0 for sentiment in sentiments]
    tweet_counts = [sentiment[5] if len(sentiment) > 5 else 0 for sentiment in sentiments]  # Handle shorter tuples

    bar_width = 0.15
    x = range(len(brands))

    plt.figure(figsize=(16, 8))
    plt.bar(x, very_positive, color='darkgreen', width=bar_width, edgecolor='grey', label='Very Positive')
    plt.bar([p + bar_width for p in x], positive, color='green', width=bar_width, edgecolor='grey', label='Positive')
    plt.bar([p + bar_width*2 for p in x], neutral, color='blue', width=bar_width, edgecolor='grey', label='Neutral')
    plt.bar([p + bar_width*3 for p in x], negative, color='orange', width=bar_width, edgecolor='grey', label='Negative')
    plt.bar([p + bar_width*4 for p in x], very_negative, color='red', width=bar_width, edgecolor='grey', label='Very Negative')

    plt.xlabel('Brands', fontweight='bold')
    plt.ylabel('Percentage', fontweight='bold')
    plt.xticks([p + bar_width*2 for p in x], brands, rotation=90)
    plt.title(title)
    plt.legend()

    for i in x:
        plt.text(i, max(very_positive[i], positive[i], neutral[i], negative[i], very_negative[i]) + 1, f'Tweets: {tweet_counts[i]}', ha='center', fontweight='bold')

    plt.show()

def main():
    # Path to your extracted CSV file
    csv_file_path = '/content/drive/MyDrive/twcs.csv'  # Make sure this path points to your CSV file

    # Check if the file exists
    if not os.path.isfile(csv_file_path):
        print(f"File not found: {csv_file_path}")
        return

    # Read the CSV file
    try:
        tweets = pd.read_csv(csv_file_path, on_bad_lines='skip', quoting=3)
    except Exception as e:
        print(f"Error reading the CSV file: {e}")
        return

    # Load SST-5 dataset and preprocess it
    sentences = pd.read_csv('/content/datasetSentences.txt', sep='\t')
    labels = pd.read_csv('/content/sentiment_labels.txt', sep='|')
    dictionary = pd.read_csv('/content/dictionary.txt', sep='|', header=None, names=['phrase', 'phrase ids'])
    splits = pd.read_csv('/content/datasetSplit.txt', sep=',')

    # Merge sentences with their phrase IDs
    sentences = sentences.merge(dictionary, left_on='sentence', right_on='phrase')
    sentences = sentences.drop('phrase', axis=1)

    # Merge sentences with their sentiment labels
    sentences = sentences.merge(labels, on='phrase ids')

    # Merge sentences with their dataset split
    sentences = sentences.merge(splits, on='sentence_index')

    # Drop unnecessary columns
    sentences = sentences.drop(['sentence_index', 'phrase ids'], axis=1)

    # Map sentiment values to labels
    def map_sentiment(value):
        if value <= 0.2:
            return 0  # very negative
        elif value <= 0.4:
            return 1  # negative
        elif value <= 0.6:
            return 2  # neutral
        elif value <= 0.8:
            return 3  # positive
        else:
            return 4  # very positive

    sentences['sentiment'] = sentences['sentiment values'].apply(map_sentiment)
    sentences = sentences.drop('sentiment values', axis=1)

    # Split the dataset into train, test, and validation sets
    train_set = sentences[sentences['splitset_label'] == 1].drop('splitset_label', axis=1)
    test_set = sentences[sentences['splitset_label'] == 2].drop('splitset_label', axis=1)
    val_set = sentences[sentences['splitset_label'] == 3].drop('splitset_label', axis=1)

    print("Train set:", train_set.shape)
    print("Test set:", test_set.shape)
    print("Validation set:", val_set.shape)

    sentiment_analyzer = SentimentAnalyzer()
    train_encodings = sentiment_analyzer.tokenizer(train_set['sentence'].tolist(), padding=True, truncation=True, return_tensors="pt")
    val_encodings = sentiment_analyzer.tokenizer(val_set['sentence'].tolist(), padding=True, truncation=True, return_tensors="pt")

    # Convert PyTorch tensors to lists before adding them as columns
    train_set = Dataset.from_dict({
        'input_ids': train_encodings['input_ids'].tolist(),
        'attention_mask': train_encodings['attention_mask'].tolist(),
        'labels': train_set['sentiment'].tolist()
    })

    val_set = Dataset.from_dict({
        'input_ids': val_encodings['input_ids'].tolist(),
        'attention_mask': val_encodings['attention_mask'].tolist(),
        'labels': val_set['sentiment'].tolist()
    })

    sentiment_analyzer.fine_tune_model(train_set, val_set)

    # Perform sentiment analysis on tweets

    chunk_size = 50000

    tweets = pd.DataFrame()
    total_chunks = sum(1 for _ in pd.read_csv(csv_file_path, chunksize=chunk_size))
    processed_chunks = 0

    for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size):
        chunk = sentiment_analyzer.analyze_sentiments(chunk)
        tweets = pd.concat([tweets, chunk])
        processed_chunks += 1
        print(f"Processed chunk {processed_chunks}/{total_chunks}")

    # List of brands to analyze
    brands = [
        'AppleSupport', 'AmazonHelp', 'Uber_Support', 'Delta', 'SpotifyCares',
        'Tesco', 'AmericanAir', 'comcastcares', 'TMobileHelp', 'British_Airways',
        'SouthwestAir', 'Ask_Spectrum', 'hulu_support', 'ChipotleTweets', 'sprintcare',
        'VirginTrains', 'AskPlayStation', 'XboxSupport', 'UPSHelp', 'sainsburys'
    ]

    # Analyze initial customer tweets and customer responses for each brand separately
    initial_sentiments = []
    response_sentiments = []

    for brand in brands:
        initial_sentiments.append(analyze_initial_tweets_by_brand(tweets, brand))
        response_sentiments.append(analyze_responses_by_brand(tweets, brand))

    # Plot the sentiment analysis results
    plot_sentiment_analysis(brands, initial_sentiments, 'Sentiment Analysis of Initial Customer Tweets')
    plot_sentiment_analysis(brands, response_sentiments, 'Sentiment Analysis of Customer Responses to Brand Tweets')

if __name__ == "__main__":
    main()
